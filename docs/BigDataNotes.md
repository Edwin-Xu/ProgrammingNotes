# BigData NOTES

## TODO

MPP产品：

- Clickhouse
- Presto
- GreenPlum
- Impala
- Pinot
- Kylin
- 关系与区分



HUE：Hadoop UI

## BASIC

### 大数据知识体系

对海量数据进行存储、计算、分析、挖掘处理需要依赖一系列的大数据技术，而大数据技术又涉及了分布式计算、高并发处理、高可用处理、集群、实时性计算等。本文对大数据技术知识体系进行划分，共分为**基础技术、数据采集、数据传输、数据组织集成、数据应用、数据治理**，进行相关的阐述说明，并列出目前业界主流的相关框架、系统、数据库、工具等。

![img](_images/BigDataNotes.asserts/v2-b57a6e21af94c99935a0dcb73fe81a7b_1440w.jpg)

#### 基础技术

##### 数据分片路由

在大数据背景下，数据规模已经由 GP 跨越大屏 PB 的级别，单机明显已经无法存储和处理如此规模大的数据量，只能依靠大规模集群来对这些数据进行存储和处理，对于海量的数据，通过数据分片（Shard/Partition）来将数据进行切分大屏不同机器中，分片之后，如何能够找到某一条记录，这就是数据的分片和路由。

##### **数据复制&一致性**

在大数据的存储系统中，为了增加系统的可靠性，往往会将同一份数据存储多个副本，数据如何复制？以及数据复制之后带来的一致性问题如何解决？

![img](_images/BigDataNotes.asserts/v2-2f4df2df2857877cd82d2c23ea3eec8d_1440w.jpg)

##### **算法和数据结构**

对于大数据或者大规模的分布式系统来说，如何能够高效快速地进行海量数据的处理非常关键，而采用合适的数据结构和算法对于达成此目标至关重要。 比如，Bloom Filter，SkipList（跳表），**LSM**树（Log-Structured Merge-Tree），HashTree，**Cuckoo**哈希等。

#### 数据采集

大数据的采集处于大数据生命周期的第一个环节，从数据采集的类型看不仅仅要涵盖基础的结构化数据，半结构化数据，以及非结构化数据，音频，视频，图像等。常见的数据采集方式包括**系统日志的采集**，**外部数据网络数据采集**，设备数据采集。

##### **系统日志采集**

系统日志采集主要用于对数据库、系统、服务器等运行状态，行为事件等数据抓取

- **埋点**：**浏览器（PC）打点、无线客户端、服务端打点**。
- 数据采集框架：**Chukwa**、Splunk **Forwarder**、**Flume**、Fluentd、Logstash、Scribe。

##### **网络数据采集**

网络数据的采集主要是通过爬虫或者公开API等方式从网站中获取数据，数据的内容可以是文本，视频，图片数据等。

- 爬虫技术：Nutch、Heritrix、Scrapy、WebCollector。

##### **设备数据采集**

设备数据采集主要是指针对一些物理设备的数据采集，常见的如传感器，探针等。

#### 数据传输

经过采集的数据通过数据通道被传输存储。集中存储的数据源的数据发生变化也能通过数据通道尽快地通知对数据敏感的相应应用或者系统构建，使得它们能够尽快的捕获数据的变化。

数据传输包含如下相关技术：**消息队列、数据同步、数据订阅、序列化**。

##### **消息队列**

消息队列是涉及大规模分布式系统时候经常使用的中间件产品，主要解决日**志搜集，应用耦合，异步消息，流量削锋**等问题实现**高性能，高可用，可伸缩和最终一致性架构**。

##### 数据同步

在数据仓库建模中，**未经任何加工处理的原始业务层数据**，我们称之为 **ODS (Operational Data Store)** 数据。在互联网企业中，常见的 ODS 数据有**业务日志数据（Log）**和**业务 DB 数据**（DB）两类。

对于业务 DB 数据来说，从 MySQL 等关系型数据库的业务数据进行采集，然后导入到数据仓库中，是进一个重要环节。如何准确、高效地把 MySQL 数据同步到数据仓库中？一般常用的解决方案是批量取数并 Load。数据同步解决各个数据源之间稳定高效的数据同步功能。

##### 数据订阅

数据订阅功能旨在帮助用户获取实时增量数据，用户能够根据自身业务需求自由消费增量数据，例如实现缓存更新策略、业务异步解耦、异构数据源数据实时同步及含复杂 ETL 的数据实时同 步等多种业务场景。

####  数据组织集成

大数据存储面向**海量、异构、大规模结构化非结构化**等数据提供高性能高可靠的存储以及访问能力，通过优化存储优化存储基础设施、提供高性能。高吞吐率、大容量的数据存储方案，解决巨大数据量的存储问题，同时为大规模数据分析、计算、加工提供支撑。

![img](_images/BigDataNotes.asserts/v2-6b80ad5954c3246b5f429dd1a5204d89_720w.jpg)

##### 物理存储

根据服务器类型，我们将存储的分类分为：

- 封闭系统的存储（封闭系统主要指大型机）
- 开放系统的存储（开放系统指基于 Windows、UNIX、Linux 等操作系统的服务器）

开放系统的存储分为：

- 内置存储
- 外挂存储

外挂存储根据连接的方式分为：

- 直连式存储（Direct-Attached Storage，简称 DAS）
- 网络化存储（Fabric-Attached Storage，简称 FAS）

网络化存储根据传输协议又分为：

- 网络接入存储（Network-Attached Storage，简称 NAS）
- 存储区域网络（Storage Area Network，简称 SAN）

![img](_images/BigDataNotes.asserts/v2-e70402f4e7529b89bcfea87c61d54d92_720w.jpg)

##### **分布式文件/对象存储系统**

分布式存储系统面向海量数据的存储访问与共享需求，提供基于**多存储节点的高性能，高可靠和可伸缩性**的数据存储和访问能力，实现分布式存储节点上多用户的访问共享。

目前业界比较流行的分布式存储系统如下：**HDFS、OpenStack Swift、Ceph、GlusterFS、Lustre、AFS、OSS**。

##### **分布式关系型数据库**

目前业界比较流行的分布式关系型数据库如下：DRDS、TiDB（PingCAP）、Spanner（Google），CockroachDB (蟑螂数据库)，阿里OceanBase，腾讯的TDSQL，GreenPlum、Cobar、Aurora、Mycat等。

##### 分析型数据库

分析数据库是**面向分析应用**的数据库，与传统的数据库不同，它可以对数据进行**在线统计、数据在线分析、随即查询**等发掘信息数据价值的工作，是数据库产品一个重要的分支。

目前业界比较流行的分析型数据库如下：**Kylin**、AnalyticDB、**Druid**、**Clickhouse**、Vertica、MonetDB、InfiniDB、LucidDB。

##### 搜索引擎

大数据时代，如何帮助用户从海量信息中快速准确搜索到目标内容，就需要搜索引擎。大数据搜索引擎是一个**提供分布式，高性能、高可用、可伸缩的搜索和分析系统**。

目前常见的搜索引擎技术如下：**Elasticsearch**、**Solr**、**OpenSearch**。

##### 图数据库

图数据库源起欧拉和图理论，也可称为面向/基于图的数据库，对应的英文是 Graph Database。图形数据库是 NoSQL 数据库的一种类型，它应用图形理论存储实体之间的关系信息。

图形数据库是一种非关系型数据库，它应用图形理论存储实体之间的关系信息。最常见例子就是社会网络中人与人之间的关系。图数据库的基本含义是以“图”这种数据结构存储和查询数据，而不是存储图片的数据库。它的数据模型主要是以节点和关系（边）来体现，也可处理键值对。它的优点是快速解决复杂的关系问题。

目前业界比较流行的图数据库如下：Titan、Neo4J、ArangoDB、OrientDB、MapGraph、ALLEGROGRAPH。

##### 列式数据库

列式数据库是以列相关存储架构进行数据存储的数据库，主要适合于批量数据处理和即时查询。相对应的是行式数据库，数据以行相关的存储体系架构进行空间分配，主要适合于大批量的数据处理，常用于联机事务型数据处理。

目前业界比较流行的列存储数据库如下：Phoenix、Cassandra、**Hbase**、**Kudu**、Hypertable。

##### 文档数据库

文档型数据库是 NoSQL 中非常重要的一个分支，它主要用来存储、索引并管理面向文档的数据或者类似的半结构化数据。

目前业界比较流行的文档型数据库如下：MongoDb、CouchDB、OrientDB、MarkLogic。

##### 键值数据库

目前业界比较流行的键值存储数据库如下：Redis、Memcached、Tair。

#### 数据计算

大数据计算主要完成**海量数据并行处理、分析挖掘**等面向业务需求。大数据计算通过将海量的数据分片，多个计算节点并行化执行，实现高性能、高可靠的数据处理，同时提供分布式任务管理和调度的支撑。针对不同的数据处理需求，主要有**大规模批量处理、流式计算、图计算、即席分析**等多种计算。

![img](_images/BigDataNotes.asserts/v2-70b18a9199661f6a4a85d18b28f7c013_720w.jpg)

##### **流式计算**

流式计算：利用分布式的思想和方法，对海量“流”式数据进行实时处理。流式计算更加强调计算数据流和低时延。这边所谓的**流数据（ streaming data）是一种不断增长的，无限的数据集**。

流式计算是否等于实时计算？习惯上实时和流式等价，但其实这种观点并不完全正确。数据的发生的时间和处理时间有可能是不一致的，只能说**流式计算是一种低延迟的计算方式**。

注意：本文将微批处理和流处理混在一起。

业界常见的流式计算框架：**Storm**、**Flink**、Yahoo S4、**Kafka Stream**、Twitter Heron、Apache Samza、**Spark Streaming**。

##### **大规模批量计算**

**batch compute**

大规模批量计算是对存储的**静态数据**进行大规模并行批处理的计算。**批量计算是一种批量、高时延、主动发起的计算**。习惯上我们认为**离线和批量等价**，但其实是不准确的。

**离线计算一般是指数据处理的延迟**。这里有两方面的含义第一就是**数据是有延迟的**，第二是是**时间处理是延迟**。在数据是实时的情况下，假设一种情况：当我们拥有一个非常强大的硬件系统，可以毫秒级的处理 Gb 级别的数据，那么批量计算也可以毫秒级得到统计结果。

业界常见的**大规模批量计算框架**：Tez、**MapReduce**、**Hive**、**Spark**、Pig、大数据的编程模型 Apache Beam。

##### **即席查询分析 (ad-hoc query)**

大数据进行**即席查询**分析近两年日益成为关注领域。**即席查询（Ad Hoc）**是**用户根据自己的需求，灵活的选择查询条件，系统能够根据条件快速的进行查询分析返回结果**。即席查询和分析的计算模式兼具了良好的**时效性与灵活性**，**是对`批处理，流计算`两大计算模式有力补充**。大规模批量计算解决了大数据量批处理的问题，而**即席查询分析则解决了适合商业智能分析人员的便捷交互式分析**的问题。 业界常见的框架：**Impala**、Hawq、Dremel、Drill、Phoenix、Tajo、**Presto**、Hortonworks Stinger。



AD-HOC ：以单独的SQL语句的形式执行的查询就是即席查询，比如说：在C#程序里嵌入的SQL语句，或者在SSMS里的新建查询窗口

自己键入的SQL代码就是即席查询。

而将SQL代码放入存储过程里面，以**存储过程**或者**函数**或者**触发器**来执行的查询就不是即席查询，即席：当场，就是当场去查询



ad hoc是拉丁语，意为for this. 为了这个目标

##### **全量计算 & 增量计算**

很多大数据的任务中，数据是一个**增量收集和更新**的过程，这时候对于数据的处理可以使是**全量加上增量计算**的方式。增量计算只对部分新增数据进行计算来极大提升计算过程的效率，可应用到数据增量或周期性更新的场合。典型例子就是搜索引擎的周期性索引更新。

相关基础知识：Lambda 架构、Kappa 架构、IOTA 架构。

业界常见框架：Microsoft Kineograph、Galaxy、Google Percolator、**Druid**。

##### 图计算

图计算是一类在实际应用中非常常见的计算类型。许多大数据都是以大规模图或网络的形式呈现，如社交网络、传染病传播途径、交通事故对路网的影响许多非图结构的大数据，也常常会被转换为图模型后进行分析。图数据结构很好地表达了数据之间的关联性。要处理规模巨大的图数据，传统的单机处理方式已经无力处理，必须采用大规模机器集群构成的并行数据库。

相关基础知识：GAS 编程模型、BSP 模型、节点为中心编程模型、计算范型。

业界常见框架：Pregel、GraphChi、Spark GraphX、PowerGrah、Apache Giraph、Apache Hama。

##### 分布式协调系统

大规模分布式系统中需要解决**各种类型的协调需求**，例如当当系统中加入一个进程或者物理机，如何自动获取参数和配置，当进程和物理机发生改变如何通知其他进程；单主控服务发生瘫痪，如何能够从备份中选取新的主控服务。**分布式协调系统适用于大型的分布式系统，可以提供统一命名服务、状态同步服务、集群管理、分布式应用配置项的管理等服务**。

业界常见框架：Chubby、阿里 Diamond、阿里 ConfigServer、**zookeeper**、**Eureka**、**Consul**。

##### **集群资源管理和调度**

资源管理调度的本质是**集群、数据中心级别的资源统一管理和分配**，以提高效率。其中，**多租户、弹性计算、动态分配**是资源管理系统要核心解决问题。

管理调度框架：Omega、Brog、Mesos、Corona、**Yarn**、Torca。

管理和监控工具：Ambari、Chukwa、Hue。

##### **工作流管理引擎**

随着企业的发展，他们的工作流程变得更加复杂，越来越多的有着错综复杂依赖关系的工作流需要增加监控，故障排除。如果没有明确的血缘关系。就可能出现问责问题，对元数据的操作也可能丢失。这就是有向无环图（DAG），数据管道和工作流管理器发挥作用的地方。

复杂的工作流程可以通过 DAG 来表示。DAG 是一种图结构。信息必须沿特定方向在顶点间传递，但信息无法通过循环返回起点。DAG 的构建是数据管道，或者是一个进程的输入成为下一个进程的输入的顺序进程。

构建这些管道可能会很棘手，但幸运的是，有几个开源的工作流管理器可用于解决这个问题，允许程序员专注于单个任务和依赖关系。

业界常见框架：Oozie、Azkaban、Luigi、Airflow。

##### **数据仓库**

随着数据库技术和管理系统的不断发展和普及，人们已不再满足于一般的业务处理。同时随着数据量的不断增大，如何能够更好地利用数据，将数据转化成商业价值，已经成为人们越来越关心的问题。

举例来说，数据库系统可以很好地解决事务处理，实现对数据的“增删改查”等功能，但是却不能提供很好的决策分析支持。因为事务处理首先考虑响应的及时性，多数情况都是在处理当前数据，而决策分析需要考虑的是数据的集成性和历史性，可能对分析处理的时效性要求不高。所以为了提高决策分析的有效性和完整性，人们逐渐将一部分或者大部分数据从联机事物处理系统中剥离出来，形成今天的数据仓库系统。

##### **数据挖掘**

分析挖掘是通过算法从大数据红提炼出具有价值的信息和知识的过程。以机器和算法为主导，充分发挥机器在数据分析挖掘中的效率和可靠性的优势，提供对结构化数据以及文本、图像、视频和语言等非结构数据分析挖掘。数据分析挖掘包括一些通用的数据挖掘方法，也包括深度学习，机器学习，统计分析等。

![img](_images/BigDataNotes.asserts/v2-04adea780b7a679e1538a0876fd7b90f_720w.jpg)

#### 数据应用

![img](_images/BigDataNotes.asserts/v2-5bbd0fbe7cdc96b077b19626802e9c17_720w.jpg)

![img](_images/BigDataNotes.asserts/v2-9695d5f4b69a251dd39e0f00cd196f0b_720w.jpg)

![img](_images/BigDataNotes.asserts/v2-8cc67d4f68a93550f0efc44643da4a7b_720w.jpg)

![img](_images/BigDataNotes.asserts/v2-8051f6de26ac0a5acbae123f4712136b_720w.jpg)

![img](_images/BigDataNotes.asserts/v2-666d93d49a8d16f025cda0ce62c8182d_720w.jpg)

![img](_images/BigDataNotes.asserts/v2-b86a1c049e14a6e5824775545d0a40ca_720w.jpg)

![img](_images/BigDataNotes.asserts/v2-41f252604c48536e427f9824c4e3022d_720w.jpg)

![img](_images/BigDataNotes.asserts/v2-ef51787aea60a442263a0d85127d1f5a_720w.jpg)







### TECH

- Hadoop
- hdfs
- hive
- flume
- oozie
- hbase
- kafka
- spark
- flink



### 数据类型

**热数据**：是需要被计算节点频繁访问的在线类数据。
**冷数据**：是对于离线类不经常访问的数据，比如企业备份数据、业务与操作日志数据、话单与统计数据。

热数据就近计算，冷数据集中存储







### 学习路线

![image-20210805203347911](_images/BigDataNotes.asserts/bigData.jpg)

## 概述

### 基本说明

- HBASE是一个**高可靠、高性能、面向列、可伸缩、实时读写**的**分布式**数据库
- 利用**Hadoop** HDFS作为其文件系统
- 利用**Zookeeper**作为其分布式协同服务
- 主要用来存储**非结构化、半结构化**的**松散数据**[**列存NoSQL数据库**]

### VS 关系型数据库

![image-20210805203347911](_images/BigDataNotes.asserts/image-20210805203347911.png)



### 使用场景

- 数据规模大
- 实时的点查询
- 容忍NoSQL短板
- 数据分析需求不多



## 架构

### 集群架构

![image-20210805203734206](_images/BigDataNotes.asserts/image-20210805203734206.png)



## 文件存储

### ORC文件格式

ORC：`Optimized Row Columnar`，ORC文件格式是一种Hadoop生态圈中的列式存储格式，最初产生自Hive，用于降低数据存储空间和加速查询速度。

和Parquet类似，它并不是一个单纯的列式存储格式，仍然是首先`根据行组分割整个表`，在每一个`行组内进行按列存储`

ORC文件是自描述的，它的元数据使用Protocol Buffers序列化，并且文件中的数据尽可能的压缩以降低存储空间的消耗，目前也被Spark SQL、Presto等查询引擎支持，但是Impala对于ORC目前没有支持，仍然使用Parquet作为主要的列式存储格式。

2015年ORC项目被Apache项目基金会提升为Apache顶级项目。

ORC具有以下一些优势:

1. ORC是列式存储，有多种文件压缩方式，并且有着很高的压缩比。
2. 文件是可切分（Split）的。因此，在Hive中使用ORC作为表的文件存储格式，不仅节省HDFS存储资源，查询任务的输入数据量减少，使用的MapTask也就减少了。
3. 提供了多种索引，row group index、bloom filter index。
4. ORC可以支持复杂的数据结构（比如Map等）



和Parquet不同，ORC原生是不支持嵌套数据格式的，而是通过对复杂数据类型特殊处理的方式实现嵌套格式的支持

和Parquet类似，ORC文件也是以二进制方式存储的，所以是不可以直接读取，ORC文件也是自解析的，它包含许多的元数据，这些元数据都是同构ProtoBuffer进行序列化的



### Parquet



## 使用

### 使用规范

![image-20210805203836718](_images/BigDataNotes.asserts/image-20210805203836718.png)





## 大数据概念

### MPP

MPP全称Massive Parallel Processing，在不少文章中会先拿SMP、NUMA来跟MPP进行对比，但前2者其实是硬件层面的系统架构

- SMP（SymmetricMulti-Processor）是用来扩展我们单个CPU（Single-Processor）情况，一般情况下我们的PC都是单个CPU（一个CPU可以有多核），CPU和内存之间由总线连接，为了扩展（服务器）硬件性能，在同一个系统总线上可以挂载多个CPU单元+多个内存，大家对称无差别的访问内存，访问内存的耗时是一样的。由于在对称访问内存的过程中必定会出现共享资源冲突的情况，比如CPU1要写内存变量a，CPU2要读或者写a，那就需要相应的同步机制，这也限制了CPU扩展能力，不能无限在上面扩展CPU，一般SMP服务器CPU利用率最好的情况是2-4个CPU。
- UMA（Non-UniformMemory Access）也是为了扩展机器性能，但同时也为了解决SMP扩展性问题。既然过多CPU们共享内存那么多问题，那就划分下，2-4个CPU组成一个CPU模块，一个CPU模块分配一块独立的内存，这个CPU模块内的CPU能像SMP机器一样高效的访问这块内存资源；同时这种CPU模块+独立内存的组合可以进行扩展，由于又是在同一个机器内，那必然会出现CPU模块A中的CPU想访问模块B中的内存，所以NUMA架构会在各个CPU模块直接建立互联模块（称为Crossbar Switch），但由于架构上已经把内存划分成2种类型：就近内存和远端内存，所以访问内存的速度也有所差异。一般NUMA架构的CPU能支持到几十到上百个，但由于内存访问速度有差异的缺陷，CPU增加无法带来性能线性增加，一般8倍的CPU只能带来3倍性能的提升。

上面提到的2种都是硬件系统架构，为了解决SMP和NUMA扩展性缺陷的问题，提出了MPP的“服务”架构，注意这不是硬件架构，而是一种软件服务架构思想，是一种系统扩展方式。对外MPP呈现出来的是一个独立的服务形态。

Share Nothing是MPP的出发点。MPP“服务”架构底层会有多个SMP机器（应该也支持NUMA，不关心具体的硬件架构），在这之上还需要有一个独立的任务切分和调度的服务，其主要是把服务的功能划分到各个下面的节点机器，下面的机器运行的代码逻辑是一样的，只不过是用本地计算资源（CPU）去处理的本地的数据（Memory+Disk），并且这些节点是并行运行的，所以运行的效率也是非常高的

下面我们看看MPP的应用领域，MPP是种软件服务架构，最先应用的就是数据库领域。这也是很好理解，一般服务的瓶颈最容易出现在DB，各种分库分表为了也是解决DB的扩展性问题

MPP在数据库领域的应用应该归属于分布式数据库，而且不仅限于OLTP，更多场景应用于OLAP。

对比MPP和Sql on Hadoop的话其实是2个理念之间的对比：MPP和Batch

Batch其实是另外一种Share Nothing的实现

在存储层面，MPP是基于key去做划分，而Batch是基于Block去做划分，前者带有明显的业务含义，而后者则不带任何含义，拜托业务约束，扩展性上也就更好了



在数据库**非共享集群**中，每个节点都有独立的磁盘存储系统和内存系统，业务数据根据数据库模型和应用特点划分到各个节点上，每台数据节点通过专用网络或者商业通用网络互相连接，彼此协同计算，作为整体提供数据库服务。**非共享数据库集群有完全的可伸缩性、高可用、高性能、优秀的性价比、资源共享等优势。**

简单来说，MPP 是将任务并行的分散到多个服务器和节点上，在每个节点上计算完成后，将各自部分的结果汇总在一起得到最终的结果。























### ODS

ODS全称是Operational Data Store，即操作数据存储

Bill.Inmon的定义：ODS是一个面向主题的、集成的、可变的、当前的细节数据集合，用于支持企业对于即时性的、操作性的、集成的全体信息的需求。常常被作为数据仓库的过渡，也是数据仓库项目的可选项之一。

而Kimball的定义：操作型系统的集成，用于当前、历史以及其它细节查询(业务系统的一部分)；为决策支持提供当前细节数据(数据仓库的一部分)。



DB 是现有的数据来源，可以为mysql、SQLserver、文件日志等，为数据仓库提供数据来源的一般存在于现有的业务系统之中。

ETL的是 Extract-Transform-Load 的缩写，用来描述将数据从来源迁移到目标的几个过程：

- Extract，数据抽取，也就是把数据从数据源读出来。
- Transform，数据转换，把原始数据转换成期望的格式和维度。如果用在数据仓库的场景下，Transform也包含数据清洗，清洗掉噪音数据。
- Load  数据加载，把处理后的数据加载到目标处，比如数据仓库。

ODS(Operational Data Store) 操作性数据，是作为数据库到数据仓库的一种过渡，ODS的数据结构一般与数据来源保持一致，便于减少ETL的工作复杂性，而且ODS的数据周期一般比较短。ODS的数据最终流入DW
 +DW (Data Warehouse)数据仓库，是数据的归宿，这里保持这所有的从ODS到来的数据，并长期报错，而且这些数据不会被修改。

DM(Data Mart) 数据集市,为了特定的应用目的或应用范围，而从数据仓库中独立出来的一部分数据，也可称为部门数据或主题数据。面向应用。

### 数据质量

![image-20211124155701451](_images/BigDataNotes.asserts/image-20211124155701451.png)

### 脱敏

敏感数据，脱敏

数据脱敏（Data Masking），顾名思义，是屏蔽敏感数据，对某些敏感信息（比如，身份证号、手机号、卡号、客户姓名、客户地址、邮箱地址、薪资等等 ）通过脱敏规则进行数据的变形，实现隐私数据的可靠保护。业界常见的脱敏规则有，替换、重排、加密、截断、掩码，用户也可以根据期望的脱敏算法自定义脱敏规则。

通常，良好的数据脱敏实施，需要遵循如下两个原则，**第一**，尽可能地为脱敏后的应用，保留脱敏前的有意义信息；**第二**，最大程度地防止黑客进行破解。

https://www.zhihu.com/question/372531840



### 离线计算 实时计算

离线计算，通常也称为“批处理”，表示那些离线批量、延时较高的静态数据处理过程。
离线计算适用于实时性要求不高的场景，比如离线报表、数据分析等，延时一般在分钟级或小时级，多数场景是定时周期性执行一个Job任务，任务周期可以小到分钟级，比如每五分钟做一次统计分析，大到月级别、年级别，比如每月执行一次任务。我们最熟悉的MapReduce就是一个离线计算框架，Spark SQL也通常用于离线计算任务。



实时计算，通常也称为“实时流计算”、“流式计算”，表示那些实时或者低延时的流数据处理过程。
实时计算通常应用在实时性要求高的场景，比如实时ETL、实时监控等，延时一般都在毫秒级甚至更低。目前比较流行的实时框架有Spark Streaming与Flink。其中，Spark Streaming属于微批处理，是一种把流当作一种批的设计思想，具有非常高的吞吐量但延时也较高，这使得Streaming的场景也得到了一定的限制；Flink则是事件驱动的流处理引擎，是一种把批当作一种有限的流的设计思想，具有高吞吐，低延时，高性能的特点，



### 实时查询 Vs 即席查询

实时查询
实时查询，通常也称为在线查询，是对不断变化的数据进行实时的查询，要求数据修改后能够快速被查询到。通常我们见到的实时查询多是API的方式，少数以SQL方式。在线查询场景中最常见的生态组件大概就是HBase了，HBase能够提供强一致性的低延时数据访问，非常适合一般的在线业务。



即席查询
即席查询，英文名称为Ad hoc query，起初是在数据仓库领域中用户根据特定需求定义的一种实时查询方式。通常情况下，即席查询的表现是借助于大数据SQL查询组件进行交互式查询，比如Hive、Impala、Presto等SQL查询组件。因此严格意义上说，即席查询和上述中的实时查询还是有一定区别的。

### 物化视图

物化视图(Material View)是包括一个查询结果的数据库对象，它是远程数据的的本地副本，或者用来生成基于数据表求和的汇总表。物化视图存储基于远程表的数据，也可以称为快照（类似于MSSQL Server中的Snapshot，静态快照）。

对于复制，物化视图允许你在本地维护远程数据的副本，这些副本是只读的。如果你想修改本地副本，必须用高级复制的功能。当你想从一个表或视图中抽取数据时，你可以从物化视图中抽取。对于数据仓库，创建的物化视图通常情况下是聚合视图，单一表聚合视图和连接视图。（这个是基于本地的基表或者视图的聚合）。物化视图，说白了，**就是物理表**，只不过这张表**通过oracle的内部机制可以定期更新，将一些大的耗时的表连接用物化视图实现，会提高查询的效率**。当然要打开查询重写选项；

物化视图和[视图](https://baike.baidu.com/item/视图/1302820)类似，反映的是某个查询的结果，但是和视图仅保存SQL定义不同，物化视图本身会存储数据，因此是物化了的视图



### ODS

ODS（Operational Data Store）操作性数据，是作为数据库到数据仓库的一种过渡，ODS的数据结构一般与数据来源保持一致，便于减少ETL的工作复杂性，而且ODS的数据周期一般比较短。ODS的数据最终流入DW



人们对数据的处理行为可以划分为事务型数据处理（OLTP,On-Line Transaction Processing）和分析型数据处理(OLAP,On-Line Analytic Processing)。
事务型数据处理一般放在传统的数据库(Database,DB)中进行，分析型数据处理则需要在数据仓库(Data Warehouse,DW)中进行。但是有些操作型处理并不适合放在传统的数据库上完成，也有些分析型处理不适合在数据仓库中进行，这时候就需要第三种数据存储体系，操作数据存储(Operational Data Store,ODS)系统就因此产生。它的出现，也将DB&DW两层数据架构转变成DB&ODS&DW三层数据架构。

ODS中的数据具有以下4个基本特征：
①. 面向主题的：进入ODS的数据是来源于各个操作型数据库以及其他外部数据源，数据进入ODS前必须经过 ETL过程（抽取、清洗、转换、加载等）。
②. 集成的：ODS的数据来源于各个操作型数据库，同时也会在数据清理加工后进行一定程度的综合。
③. 可更新的：可以联机修改。这一点区别于数据仓库
④. 当前或接近当前的：“当前”是指数据在存取时刻是最新的，“接近当前”是指存取的数据是最近一段时间得到的。




### DW 

DW (Data Warehouse)数据仓库，是数据的归宿，这里保持这所有的从ODS到来的数据，并长期保存，而且这些数据不会被修改。

DW是一个很大的数据存储集合，出于企业的分析性报告和决策支持目的而创建，对多样的业务数据进行筛选与整合。它为企业提供一定的BI（商业智能）能力，指导业务流程改进、监视时间、成本、质量以及控制。数据仓库是面向主题的、集成的、稳定的、随时间变化的，反应历史变化的数据集合，主要用于决策支持的数据库系统。

### DM

DM(Data Mart) 数据集市,为了特定的应用目的或应用范围，而从数据仓库中独立出来的一部分数据，也可称为部门数据或主题数据。面向应用。在数据仓库的实施过程中往往可以从一个部门的数据集市着手，以后再用几个数据集市组成一个完整的数据仓库。需要注意的就是在实施不同的数据集市时，同一含义的字段定义一定要相容，这样再以后实施数据仓库时才不会造成大麻烦。数据集市，以某个业务应用为出发点而建设的局部DW,DW只关心自己需要的数据，不会全盘考虑企业整体的数据架构和应用。

### EDW 

EDW（enterprisedatawarehouse，企业级数据仓库）



### CDC

从广泛意义上说，全球许多企业每天都需要通过频繁的数据批量处理与加载，来定期将数据从一个数据库迁移到另一个数据库(或数据仓库)。这类定期批量加载的工作，往往既耗费时间，又会消耗原始系统的大量处理能力。因此，管理员只能在业务运行的间歇期间运行数据的批量传输与复制作业，否则会产生严重的效率影响。而显然，这与24x7的不间断业务需求是背道而驰的。

近年来，**<u>变更数据捕获(Change Data Capture，CDC)</u>**已成为了在高速数据流通环境中，各种关系型数据库、云端数据库、以及数据仓库之间，进行低延迟、高可靠性且可扩展式数据复制的理想化解决方案

**CDC是指从源数据库捕获到数据和数据结构(也称为模式)的增量变更，近乎实时地将这些变更，传播到其他数据库或应用程序之处。**通过这种方式，CDC能够向数据仓库提供高效、低延迟的数据传输，以便信息被及时转换并交付给专供分析的应用程序。

在数据不断变化，且无法中断与在线数据库连接的情况下，对于各种时间敏感(time-sensitive)类信息的复制，往往也是云端迁移的重要组成部分。与批量复制相比，变更数据的捕获通常具有如下三项基本优势：

- CDC通过仅发送增量的变更，来降低通过网络传输数据的成本。
- CDC可以帮助用户根据最新的数据做出更快、更准确的决策。例如，CDC会将事务直接传输到专供分析的应用上。
- CDC最大限度地减少了对于生产环境网络流量的干扰。

四种不同的CDC方法：

#### 时间戳或版本号跟踪

数据库设计者可以在需要跟踪的数据表中，设定某一列来代表最后被修改的时间戳或版本号。例如，我们通常可以将这些列命名为：LAST_UPDATE、DATE_MODIFIED、以及VERSION_NUMBER等。那些在上一次数据捕获之后，增加了时间戳的任何行，都将被视为发生了修改。而在基于版本号的跟踪方法中，变更一旦发生，所有具有最新版本号的数据，都被视为发生了修改。

在实际应用中，您可以结合版本和时间戳两个维度，来跟踪数据库表中的数据。例如，您可以设定一条逻辑--“捕获自2021年6月22日以来，相对于3.4版发生了变更的所有数据”。

优点：

- 简单易懂。
- 数据库设计者可以自定义应用程序的逻辑构建。
- 不需要任何外部的工具。

缺点：

- 给数据库增加了额外的开销。
- 需要额外的CPU资源，来扫描表中的数据变更，并需要预留资源，以确保 LAST_UPDATE列能够可靠地追踪所有资源表。
- 被删除的行不会存在于LAST_UPDATE中。如果没有其他脚本来跟踪此类删除的话，DML语句(例如“DELETE”)将不会被传递到目标数据库处。
- 容易出错，并可能导致数据出现一致性问题。

#### 表的差异与增量

这种CDC方法使用诸如：表增量(table delta)之类的实用程序，或tablediff，去比较两个表中的数据，以发现不匹配的行。据此，您可以使用其他的脚本，将源表的差异同步到目标表上。

虽然该方法在管理已删除行的方面，比时间戳CDC的效果更好，但是它在发现差异时，所需要的CPU资源较为显著。而且此类开销会随着数据数量的增加，而呈线性增加。此外，针对源数据库或生产环境的分析查询，也可能会降低应用本身的性能。对此，您可以定期将数据库导出至暂存环境中进行比较。不过，随着数据量的增加，此类传输的成本也会呈指数级增长。

表差异的另一个问题是，它无法捕获数据的临时性变更。例如，假设有人更新了某个字段，但随后又将其变更回了原始值。那么，如果您只是运行一个简单比较的话，将无法捕获到这个变更事件。而由于diff方法本身存在着延迟，因此也无法实时执行。

优点：

- 可使用各种原生的SQL脚本，来获取变更数据的准确视图。

缺点：

- 由于此方法会用到数据源的三个副本：原始数据、先前快照和当前快照，因此整体存储需求会有所增加。
- 在那些具有繁重事务负载的应用程序中，无法得到很好的扩展。

注意：表差异和时间戳CDC方法，都不适用于真实的生产环境。因此对于大型数据集，我建议您使用如下两种CDC方法。其实，基于触发器和事务日志的变更数据跟踪方法，只是出于相同目的的两种不同的服务方式。

#### 基于触发器的CDC

-  我们需要为参与数据复制的每个表，创建三个触发器，当数据记录发生如下特定事件时，则会触发相应的操作：

1. 将新的记录插入数据表时，触发的是INSERT触发器。
2. 数据记录发生变更时，触发的是UPDATE触发器。
3. 数据记录被删除时，触发的是DELETE触发器。

- “事件历史”的影子表被存储在数据库本身，并由各种状态改变事件的序列所组成。
- 每当对象的状态发生变化时，新的事件都会被附加到该序列中。据此，有关变更记录的信息，也会被转移到“事件历史”的影子表中。
- 最后，根据历史表中的各个事件，变更会被传输到目标数据库中。

优点：

- 非常可靠且详尽。
- 影子表可以提供所有事务的不可变详细日志。

缺点：

- 每次插入、更新或删除数据行时，都需要对数据库进行多次写入，此举降低了数据库的性能。

DBA和数据工程师应当持续关注并测试，那些被添加到生产环境中的各种触发器的性能，进而决定是否可以容忍此类额外产生的开销。

#### 事务日志CDC

众所周知，数据库虽然主要会将事务日志用于备份和恢复目的，但它们也可被用于将变更复制到目标数据库或数据湖中。而在基于事务日志的CDC系统中，数据流不会被持久性存储。它们会使用Kafka去捕获变更，并将变更推送到目标数据库中。

可见，基于事务日志的CDC和基于触发器的CDC之间的主要区别在于，每个变更都将进入由数据库引擎所生成的事务日志中。也就是说，数据库引擎会使用本机事务日志(也称为重做日志)，来存储所有数据库的事件，以便在发生故障时，可以恢复数据库。它们无需执行任何应用程序级别的变更，或扫描影子表。因此，与基于触发器的CDC相比，从事务日志中恢复数据虽然更为复杂，但是会更加可行。

优点：

- 由于每个事务都不需要额外的查询，因此它对生产环境中的数据库系统的影响最小。
- 无需变更生产环境中数据库系统的架构，或添加额外的数据表。

缺点：

- 由于大多数数据库并不记录它们的事务日志格式，也不会在新的版本中公布对其实施的变更，因此DBA解析数据库的内部日志格式会较为困难。DBA有时需要在数据库的每个新版本中，去解析变更数据库的日志逻辑。
- 由于日志文件通常会被数据库引擎予以归档，因此CDC软件必须在此之前读取日志，或者能够读取已归档的日志。
- 创建可扫描的事务日志所需要的额外日志级别，可能会增加少量的性能开销。
- 当CDC应用程序发送数据时，目标数据库可能会意外地变得不可访问。它们必须缓冲未发送的数据，直到目标数据库重新联机上线。当然，如果未能完成该步骤，则可能导致数据的丢失或重复。
- 同样，如果源与目标之间的传输连接出现中断，系统也可能会发生故障，进而导致数据的丢失、记录的重复、以及需要从初始数据处重新启动加载。





### 物化视图

物化视图（Materialized View）本质是一种预计算，即把某些耗时的操作（例如JOIN、AGGREGATE）的结果保存下来，以便在查询时直接复用，从而避免这些耗时的操作，最终达到加速查询的目的。

[视图]是一种虚拟表，任何对视图的查询，都会转换为视图SQL语句的查询。而物化视图是一种特殊的物理表，物化视图会存储实际的数据，占用存储资源。



### Trino

1. Trino是通过分布式查询，高效处理大量数据的工具。要处理TB或PB级别的数据，一般是使用能够与Hadoop和HDFS进行交互的工具。Trino的设计目标就是取代这些工具，如Hive或Pig，
2. 但是除了访问HDFS。Trino也可以操作其他数据源，包括传统关系数据库和其他数据源，如Cassandra。
3. Trino旨在处理数据仓库和分析工作：数据分析、聚合大量数据并生成报告。这些工作负载通常被归类为在线分析处理（OLAP）。





## 数据仓库

https://www.jianshu.com/p/da62fb0c6a0b

### 概述

#### 什么是数据仓库

数据仓库 DataWarehouse，DW/DWH

数据仓库是一个面向主题的Subject Oriented、集成的Integrate、相对稳定的Non-Volatile、反映历史变化的Time Variant的数据集合，用于支持管理决策。

#### OLTP和OLAP

OLTP： online transaction processing，联机事务处理，主要是业务处理，需要考虑高并发、事务

OLAP：online Analytical Processing, 联机分析处理，主要是面向分析，会产生大量的查询，很少涉及增删改。

![image-20211107235131633](_images/BigDataNotes.asserts/image-20211107235131633.png)

![img](_images/BigDataNotes.asserts/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAU2ViYXN0aWVuMjM=,size_20,color_FFFFFF,t_70,g_se,x_16.png)

#### 数据库和数仓

数据库是物理存储；数仓是管理数据的体系，是一种方法论



### 拉链表 流水表 全量表 增量表

1. 全量表：每天的所有的最新状态的数据，
2. 增量表：每天的新增数据，增量数据是上次导出之后的新数据。
3. 拉链表：**维护历史状态，以及最新状态数据的一种表**，拉链表根据拉链粒度的不同，实际上相当于快照，只不过做了优化，去除了一部分不变的记录而已,**通过拉链表可以很方便的还原出拉链时点的客户记录**。
4. 流水表： 对于表的每一个修改都会记录，可以用于反映实际记录的变更。 

#### 拉链表

拉链表是针对数据仓库设计中表存储数据的方式而定义的，顾名思义，所谓拉链，就是记录历史。**记录一个事物从开始，一直到当前状态的所有变化的信息**。



拉链表通常是对账户信息的历史变动进行处理保留的结果，流水表是每天的交易形成的历史；

流水表用于统计业务相关情况，拉链表用于统计账户及客户的情况

在数仓中，一般在数仓中通过增加**begin_date,en_date**来实现拉链表，分别表示记录的生命周期起点和终点



![image-20211110165229597](_images/BigDataNotes.asserts/image-20211110165229597.png)



![image-20220103233412027](_images/BigDataNotes.asserts/image-20220103233412027.png)



拉链表回滚

假设恢复到t天之前的数据，即未融合t天数据之前的拉链表，假设标记的开始日期和结束日期分别为s、t，具体分析如下：

```json
1 当t-1>e时，s数据、e数据在t天之前产生，保留即可
2 当t-1=e时，e数据在t天产生，需修改
3 当s<t<=e时，e数据在t+n天产生，需修改
4 当s>=t时，s数据、e数据在t+n天产生，删除即可
```





### ETL

**ETL**，是英文Extract-Transform-Load的缩写，用来描述将[数据]从来源端经过抽取（extract）、[转换]（transform）、加载（load）至目的端的过程。**ETL**一词较常用在[**数据仓库**]，但其对象并不限于数据仓库。



### 全量分区与增量分区

是分区表

但是每个分区存储的数据不同：

- 增量分区中，每个分区存储的都是增量
- 全量分区中，每个分区存储的是全量

```sql
增量形式：不包含历史所有的数据，
2020-12-19 1000000 （当天数据）
2020-12-18 1200000
2020-12-17 1009000

全量形式： where dt=‘T-1’ 多表关联
2020-12-19 1000000 （当天+历史所有数据）
2020-12-18 9900000
2020-12-17 9809000

```

### 数仓分层

目前主流的数据仓库分层大多为四层,也有五层的架构，这里介绍基本的四层架构。 分别为

- 数据贴源层(ods)、
- 数据仓库明细层(dw)、
- 多维明细层(dws)
- 数据集市层(dm)。

![image-20220517152822067](_images/BigDataNotes.asserts/image-20220517152822067.png)

数据分层的目的是：减少重复计算，避免烟囱式开发，节省计算资源，靠上层次，越对应用友好，也对用户友好，希望大部分（80%以上）的需求，都用DWS，DW的表来支持就行，所以ODS层数据不能被DM层任务引用，需要抽取数据到DW,或者DWS。

 DWS汇总层应优先调用DW明细层。在调用可累加类指标计算时，DWS汇总层尽量优先调用已经产出的粗粒度汇总层，以避免大量汇总都直接从海量的明细数据层计算。

  DM层优先调用DWS，视情况小部分可以调用DW，禁止直接调用ODS数据，避免出现过度的ODS层引用、不合理的数据复制以及子集合冗余
DM层任务的深度不宜过大（建议不超过10层）。

总的来说,数据分层的目的如下：

- **清晰数据结构**：让每个数据层都有自己的作用和职责，在使用和维护的时候能够更方便和理解
- **复杂问题简化**：将一个复杂的任务拆解成多个步骤来分步骤完成，每个层只解决特定的问题
- **统一数据口径**：通过数据分层，提供统一的数据出口，统一输出口径
- **减少重复开发**：规范数据分层，开发通用的中间层，可以极大地减少重复计算的工作

**数据贴源层(ods)：**用来**储存原始数据**，**同步的脚本和数据的表**，要和原始的表有一定的联系，用于方便数据治理，数据溯源等。一般，同步的脚本，和ods的表要体现源数据库表的特征，一般表名和字段名，字段格式，**都和原始表保持一致**，同步的形式包括增量同步和全量同步。

**数据仓库明细层(dw)：**这一层存放的是**一致的、准确的、干净的数据**，即对源系统数据进行了**清洗**（去除了杂质）后的数据。一层一般来说是**按照维度建模抽取的明细数据**。通常是**星形或雪花结构**的数据。

**多维明细层(dws)：**这一层存放的是**DW层的，一些通用的汇总数据。一般是某个主题的某个维度的汇总数据，用于提供后续的业务查询**，**OLAP分析，数据分发**等。一般来说，该层的数据表会相对较少，**一张表会涵盖比较多的业务内容，由于其字段较多，因此一般也会称该层的表为宽表**。

**数据集市层(dm)：**该层主要是**提供给数据产品和数据分析使用的数据**，这层就是根据需求来抽取数据了。

一般来说，数据分层之后，还需要对开发数据的任务，进行规范，比如字段格式，字段名称拼写，主题划分等，不然单纯分层，是不足以建立好一个对开发友好，方便运维，方便取数的数仓的，这个分层就是一个货物仓库里面各个房间的划分，但是里面货物需要怎么放，放在哪个房间那个位置，我想要某个数据应该怎么找，这个就需要一整套数据开发规范，以及对应的数据地图，数据血缘关系系统的支持了。

总的来说，数据层是数仓的骨头支架，但是肌肉，心脏等这些器官，对建立一个好的数仓，也很关键。



## MaxCompute

大数据计算服务(英文名：MaxCompute)

MaxCompute（原ODPS）是一项大数据计算服务，它能提供快速、完全托管的PB级数据仓库解决方案，使您可以经济并高效的分析处理海量数据。

![image-20221012225641767](_images/BigDataNotes.asserts/image-20221012225641767.png)

**数据存储**

- 支持大规模计算存储，适用于TB以上规模的存储及计算需求，最大可达EB级别。同一个MaxCompute项目支持企业从创业团队发展到独角兽的数据规模需求；
- 数据分布式存储，多副本冗余，数据存储对外仅开放表的操作接口，不提供文件系统访问接口
- 自研数据存储结构，表数据列式存储，默认高度压缩，后续将提供兼容ORC的Ali-ORC存储格式
- 支持外表，将存储在OSS对象存储、OTS表格存储的数据映射为二维表
- 支持Partition、Bucket的分区、分桶存储
- 更底层不是HDFS，是阿里自研的盘古文件系统，但可借助HDFS理解对应的表之下文件的体系结构、任务并发机制
- 使用时，存储与计算解耦，不需要仅仅为了存储扩大不必要的计算资源

**多种计算模型**

需要说明的是，传统数据仓库场景下，实践中有大部分的数据分析需求可以通过SQL+UDF来完成。但随着企业对数据价值的重视以及更多不同的角色开始使用数据时，企业也会要求有更丰富的计算功能来满足不同场景、不同用户的需求。

MaxCompute不仅仅提供SQL数据分析语言，它在统一的数据存储和权限体系之上，支持了多种计算类型。

**MaxCompute SQL:**

TPC-DS 100% 支持，同时语法高度兼容Hive，有Hive背景开发者直接上手，特别在大数据规模下性能强大。

- 完全自主开发的compiler，语言功能开发更灵活，迭代快，语法语义检查更加灵活高效
- 基于代价的优化器，更智能，更强大，更适合复杂的查询
- 基于LLVM的代码生成，让执行过程更高效
- 支持复杂数据类型(array,map,struct)
- 支持Java、Python语言的UDF/UDAF/UDTF
- 语法：Values、CTE、SEMIJOIN、FROM倒装、Subquery Operations、Set Operations(UNION /INTERSECT /MINUS)、SELECT TRANSFORM 、User Defined Type、GROUPING SET(CUBE/rollup/GROUPING SET)、脚本运行模式、参数化视图
- 支持外表(外部数据源+StorageHandler 支持非结构化数据）

**MapReduce：**

- 支持MapReduce编程接口(提供优化增强的MaxCompute MapReduce,也提供高度兼容Hadoop的MapReduce版本)
- 不暴露文件系统，输入输出都是表
- 通过MaxCompute客户端工具、Dataworks提交作业

**MaxCompute Graph图模型：**

- MaxCompute Graph是一套面向迭代的图计算处理框架。图计算作业使用图进行建模，图由点（Vertex）和边（Edge）组成，点和边包含权值（Value）。
- 通过迭代对图进行编辑、演化，最终求解出结果
- 典型应用有：PageRank，单源最短距离算法，K-均值聚类算法等
- 使用MaxCompute Graph提供的接口Java SDK编写图计算程序并通过MaxCompute客户端工具通过jar命令提交任务

**PyODPS:**

用熟悉的Python利用MaxCompute大规模计算能力处理MaxCompute数据。

PyODPS是MaxCompute 的 Python SDK，同时也提供 DataFrame 框架，提供类似 pandas 的语法，能利用 MaxCompute 强大的处理能力来处理超大规模数据。

- PyODPS 提供了对 ODPS 对象比如 表 、资源 、函数 等的访问。
- 支持通过 run_sql/execute_sql 的方式来提交 SQL。
- 支持通过 open_writer 和 open_reader 或者原生 tunnel API 的方式来上传下载数据
- PyODPS 提供了 DataFrame API，它提供了类似 pandas 的接口，能充分利用 MaxCompute 的计算能力进行DataFrame的计算。
- PyODPS DataFrame 提供了很多 pandas-like 的接口，但扩展了它的语法，比如增加了 MapReduce API 来扩展以适应大数据环境。
- 利用map 、apply 、map_reduce 等方便在客户端写函数、调用函数的方法，用户可在这些函数里调用三方库，如pandas、scipy、scikit-learn、nltk

**Spark:**

MaxCompute提供了Spark on MaxCompute的解决方案，使MaxCompute提供的兼容开源的Spark计算服务，让它在统一的计算资源和数据集权限体系之上，提供Spark计算框架，支持用户以熟悉的开发使用方式提交运行Spark作业。

- 支持原生多版本Spark作业：Spark1.x/Spark2.x作业都可运行；
- 开源系统的使用体验：Spark-submit提交方式（暂不支持spark-shell/spark-sql的交互式），提供原生的Spark WebUI供用户查看；
- 通过访问OSS、OTS、database等外部数据源，实现更复杂的ETL处理，支持对OSS非结构化进行处理；
- 使用Spark面向MaxCompute内外部数据开展机器学习，扩展应用场景；

**交互式分析(Lightning)**

MaxCompute产品的交互式查询服务，特性如下：

- 兼容PostgreSQL：兼容PostgreSQL协议的JDBC/ODBC接口，所有支持PostgreSQL数据库的工具或应用使用默认驱动都可以轻松地连接到MaxCompute项目。支持主流BI及SQL客户端工具的连接访问，如Tableau、帆软BI、Navicat、SQL Workbench/J等。
- 显著提升的查询性能：提升了一定数据规模下的查询性能，查询结果秒级可见，支持BI分析、Ad-hoc、在线服务等场景；

**机器学习：**

- MaxCompute内建支持的上百种机器学习算法，目前MaxCompute的机器学习能力由PAI产品进行统一提供服务，同时PAI提供了深度学习框架、Notebook开发环境、GPU计算资源、模型在线部署的弹性预测服务。PAI产品与MaxCompute在项目和数据方面无缝集成





### odpscmd

MC 客户端连接工具

```shell
Usage: odpscmd [OPTION]...
where options include:
    --help                                  (-h)for help
    --config=<config_file>                  specify another config file
    --project=<prj_name>                    use project
    --endpoint=<http://host:port>           set endpoint
    -k <n>                                  will skip begining queries and start from specified position
    -r <n>                                  set retry times
    -f <"file_path;">                       execute command in file
    -e <"command;[command;]...">            execute command, include sql command
```



```sql
odpscmd.bat -e "select * from txu6_test_02"
```

```sql
# SQL文件，支持ODPS2，ODPS1不兼容Hive的 tinyint timestamp等
set odps.sql.type.system.odps2=true;

CREATE TABLE if not exists txu6_test_03(
	id int ,
	name string
)
COMMENT 'Q侧拿去花A卡v6预测结果表'
PARTITIONED BY ( 
  `dt` string COMMENT 'date');
  
select * from txu6_test_03 where dt != '';
```

odpscmd.bat -f ../mc_sql.sql



## 大数据发展

### 大数据总结

https://zhuanlan.zhihu.com/p/452628664?utm_source=wechat_session&utm_medium=social&utm_oi=597048781695488000&s_r=0

























面试题：

- 什么是数仓？
- 数仓的几个特点是什么？
- 什么是OLAP？什么是OLTP？区别是什么？
- 拉链表是什么？怎么实现拉链表？
- 同步又哪几种方式？
- 为什么要做增量？怎么做增量？
- 什么是ETL？





ELT







学习顺序

