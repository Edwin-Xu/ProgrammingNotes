# BigData NOTES

## TODO

MPP产品：

- Clickhouse
- Presto
- GreenPlum
- Impala
- Pinot
- Kylin
- 关系与区分
- 

## BASIC

### TECH

- Hadoop
- hdfs
- hive
- flume
- oozie
- hbase
- kafka
- spark
- flink

### 数据类型

**热数据**：是需要被计算节点频繁访问的在线类数据。
**冷数据**：是对于离线类不经常访问的数据，比如企业备份数据、业务与操作日志数据、话单与统计数据。

热数据就近计算，冷数据集中存储







### 学习路线

![image-20210805203347911](_images/BigDataNotes.assets/bigData.jpg)

## 概述

### 基本说明

- HBASE是一个**高可靠、高性能、面向列、可伸缩、实时读写**的**分布式**数据库
- 利用**Hadoop** HDFS作为其文件系统
- 利用**Zookeeper**作为其分布式协同服务
- 主要用来存储**非结构化、半结构化**的**松散数据**[**列存NoSQL数据库**]

### VS 关系型数据库

![image-20210805203347911](_images/BigDataNotes.assets/image-20210805203347911.png)



### 使用场景

- 数据规模大
- 实时的点查询
- 容忍NoSQL短板
- 数据分析需求不多



## 架构

### 集群架构

![image-20210805203734206](_images/BigDataNotes.assets/image-20210805203734206.png)



## 文件存储

### ORC文件格式

ORC：`Optimized Row Columnar`，ORC文件格式是一种Hadoop生态圈中的列式存储格式，最初产生自Hive，用于降低数据存储空间和加速查询速度。

和Parquet类似，它并不是一个单纯的列式存储格式，仍然是首先`根据行组分割整个表`，在每一个`行组内进行按列存储`

ORC文件是自描述的，它的元数据使用Protocol Buffers序列化，并且文件中的数据尽可能的压缩以降低存储空间的消耗，目前也被Spark SQL、Presto等查询引擎支持，但是Impala对于ORC目前没有支持，仍然使用Parquet作为主要的列式存储格式。

2015年ORC项目被Apache项目基金会提升为Apache顶级项目。

ORC具有以下一些优势:

1. ORC是列式存储，有多种文件压缩方式，并且有着很高的压缩比。
2. 文件是可切分（Split）的。因此，在Hive中使用ORC作为表的文件存储格式，不仅节省HDFS存储资源，查询任务的输入数据量减少，使用的MapTask也就减少了。
3. 提供了多种索引，row group index、bloom filter index。
4. ORC可以支持复杂的数据结构（比如Map等）



和Parquet不同，ORC原生是不支持嵌套数据格式的，而是通过对复杂数据类型特殊处理的方式实现嵌套格式的支持

和Parquet类似，ORC文件也是以二进制方式存储的，所以是不可以直接读取，ORC文件也是自解析的，它包含许多的元数据，这些元数据都是同构ProtoBuffer进行序列化的



### Parquet



## 使用

### 使用规范

![image-20210805203836718](_images/BigDataNotes.assets/image-20210805203836718.png)





## 大数据概念

### ODS

ODS全称是Operational Data Store，即操作数据存储

Bill.Inmon的定义：ODS是一个面向主题的、集成的、可变的、当前的细节数据集合，用于支持企业对于即时性的、操作性的、集成的全体信息的需求。常常被作为数据仓库的过渡，也是数据仓库项目的可选项之一。

而Kimball的定义：操作型系统的集成，用于当前、历史以及其它细节查询(业务系统的一部分)；为决策支持提供当前细节数据(数据仓库的一部分)。



DB 是现有的数据来源，可以为mysql、SQLserver、文件日志等，为数据仓库提供数据来源的一般存在于现有的业务系统之中。

ETL的是 Extract-Transform-Load 的缩写，用来描述将数据从来源迁移到目标的几个过程：

- Extract，数据抽取，也就是把数据从数据源读出来。
- Transform，数据转换，把原始数据转换成期望的格式和维度。如果用在数据仓库的场景下，Transform也包含数据清洗，清洗掉噪音数据。
- Load  数据加载，把处理后的数据加载到目标处，比如数据仓库。

ODS(Operational Data Store) 操作性数据，是作为数据库到数据仓库的一种过渡，ODS的数据结构一般与数据来源保持一致，便于减少ETL的工作复杂性，而且ODS的数据周期一般比较短。ODS的数据最终流入DW
 +DW (Data Warehouse)数据仓库，是数据的归宿，这里保持这所有的从ODS到来的数据，并长期报错，而且这些数据不会被修改。

DM(Data Mart) 数据集市,为了特定的应用目的或应用范围，而从数据仓库中独立出来的一部分数据，也可称为部门数据或主题数据。面向应用。

### 数据质量

![image-20211124155701451](_images/BigDataNotes.assets/image-20211124155701451.png)

### 脱敏

敏感数据，脱敏

数据脱敏（Data Masking），顾名思义，是屏蔽敏感数据，对某些敏感信息（比如，身份证号、手机号、卡号、客户姓名、客户地址、邮箱地址、薪资等等 ）通过脱敏规则进行数据的变形，实现隐私数据的可靠保护。业界常见的脱敏规则有，替换、重排、加密、截断、掩码，用户也可以根据期望的脱敏算法自定义脱敏规则。

通常，良好的数据脱敏实施，需要遵循如下两个原则，**第一**，尽可能地为脱敏后的应用，保留脱敏前的有意义信息；**第二**，最大程度地防止黑客进行破解。

https://www.zhihu.com/question/372531840



### 离线计算 实时计算

离线计算，通常也称为“批处理”，表示那些离线批量、延时较高的静态数据处理过程。
离线计算适用于实时性要求不高的场景，比如离线报表、数据分析等，延时一般在分钟级或小时级，多数场景是定时周期性执行一个Job任务，任务周期可以小到分钟级，比如每五分钟做一次统计分析，大到月级别、年级别，比如每月执行一次任务。我们最熟悉的MapReduce就是一个离线计算框架，Spark SQL也通常用于离线计算任务。



实时计算，通常也称为“实时流计算”、“流式计算”，表示那些实时或者低延时的流数据处理过程。
实时计算通常应用在实时性要求高的场景，比如实时ETL、实时监控等，延时一般都在毫秒级甚至更低。目前比较流行的实时框架有Spark Streaming与Flink。其中，Spark Streaming属于微批处理，是一种把流当作一种批的设计思想，具有非常高的吞吐量但延时也较高，这使得Streaming的场景也得到了一定的限制；Flink则是事件驱动的流处理引擎，是一种把批当作一种有限的流的设计思想，具有高吞吐，低延时，高性能的特点，



### 实时查询 Vs 即席查询

实时查询
实时查询，通常也称为在线查询，是对不断变化的数据进行实时的查询，要求数据修改后能够快速被查询到。通常我们见到的实时查询多是API的方式，少数以SQL方式。在线查询场景中最常见的生态组件大概就是HBase了，HBase能够提供强一致性的低延时数据访问，非常适合一般的在线业务。



即席查询
即席查询，英文名称为Ad hoc query，起初是在数据仓库领域中用户根据特定需求定义的一种实时查询方式。通常情况下，即席查询的表现是借助于大数据SQL查询组件进行交互式查询，比如Hive、Impala、Presto等SQL查询组件。因此严格意义上说，即席查询和上述中的实时查询还是有一定区别的。

### 物化视图

物化视图(Material View)是包括一个查询结果的数据库对象，它是远程数据的的本地副本，或者用来生成基于数据表求和的汇总表。物化视图存储基于远程表的数据，也可以称为快照（类似于MSSQL Server中的Snapshot，静态快照）。

对于复制，物化视图允许你在本地维护远程数据的副本，这些副本是只读的。如果你想修改本地副本，必须用高级复制的功能。当你想从一个表或视图中抽取数据时，你可以从物化视图中抽取。对于数据仓库，创建的物化视图通常情况下是聚合视图，单一表聚合视图和连接视图。（这个是基于本地的基表或者视图的聚合）。物化视图，说白了，**就是物理表**，只不过这张表**通过oracle的内部机制可以定期更新，将一些大的耗时的表连接用物化视图实现，会提高查询的效率**。当然要打开查询重写选项；

物化视图和[视图](https://baike.baidu.com/item/视图/1302820)类似，反映的是某个查询的结果，但是和视图仅保存SQL定义不同，物化视图本身会存储数据，因此是物化了的视图



### ODS

ODS（Operational Data Store）操作性数据，是作为数据库到数据仓库的一种过渡，ODS的数据结构一般与数据来源保持一致，便于减少ETL的工作复杂性，而且ODS的数据周期一般比较短。ODS的数据最终流入DW



人们对数据的处理行为可以划分为事务型数据处理（OLTP,On-Line Transaction Processing）和分析型数据处理(OLAP,On-Line Analytic Processing)。
事务型数据处理一般放在传统的数据库(Database,DB)中进行，分析型数据处理则需要在数据仓库(Data Warehouse,DW)中进行。但是有些操作型处理并不适合放在传统的数据库上完成，也有些分析型处理不适合在数据仓库中进行，这时候就需要第三种数据存储体系，操作数据存储(Operational Data Store,ODS)系统就因此产生。它的出现，也将DB&DW两层数据架构转变成DB&ODS&DW三层数据架构。

ODS中的数据具有以下4个基本特征：
①. 面向主题的：进入ODS的数据是来源于各个操作型数据库以及其他外部数据源，数据进入ODS前必须经过 ETL过程（抽取、清洗、转换、加载等）。
②. 集成的：ODS的数据来源于各个操作型数据库，同时也会在数据清理加工后进行一定程度的综合。
③. 可更新的：可以联机修改。这一点区别于数据仓库
④. 当前或接近当前的：“当前”是指数据在存取时刻是最新的，“接近当前”是指存取的数据是最近一段时间得到的。




### DW 

DW (Data Warehouse)数据仓库，是数据的归宿，这里保持这所有的从ODS到来的数据，并长期保存，而且这些数据不会被修改。

DW是一个很大的数据存储集合，出于企业的分析性报告和决策支持目的而创建，对多样的业务数据进行筛选与整合。它为企业提供一定的BI（商业智能）能力，指导业务流程改进、监视时间、成本、质量以及控制。数据仓库是面向主题的、集成的、稳定的、随时间变化的，反应历史变化的数据集合，主要用于决策支持的数据库系统。

### DM

DM(Data Mart) 数据集市,为了特定的应用目的或应用范围，而从数据仓库中独立出来的一部分数据，也可称为部门数据或主题数据。面向应用。在数据仓库的实施过程中往往可以从一个部门的数据集市着手，以后再用几个数据集市组成一个完整的数据仓库。需要注意的就是在实施不同的数据集市时，同一含义的字段定义一定要相容，这样再以后实施数据仓库时才不会造成大麻烦。数据集市，以某个业务应用为出发点而建设的局部DW,DW只关心自己需要的数据，不会全盘考虑企业整体的数据架构和应用。









## 数据仓库

https://www.jianshu.com/p/da62fb0c6a0b

### 概述

#### 什么是数据仓库

数据仓库 DataWarehouse，DW/DWH

数据仓库是一个面向主题的Subject Oriented、集成的Integrate、相对稳定的Non-Volatile、反映历史变化的Time Variant的数据集合，用于支持管理决策。

#### OLTP和OLAP

OLTP： online transaction processing，联机事务处理，主要是业务处理，需要考虑高并发、事务

OLAP：online Analytical Processing, 联机分析处理，主要是面向分析，会产生大量的查询，很少涉及增删改。

![image-20211107235131633](_images/BigDataNotes.assets/image-20211107235131633.png)

#### 数据库和数仓

数据库是物理存储；数仓是管理数据的体系，是一种方法论



### 拉链表 流水表 全量表 增量表

1. 全量表：每天的所有的最新状态的数据，
2. 增量表：每天的新增数据，增量数据是上次导出之后的新数据。
3. 拉链表：**维护历史状态，以及最新状态数据的一种表**，拉链表根据拉链粒度的不同，实际上相当于快照，只不过做了优化，去除了一部分不变的记录而已,**通过拉链表可以很方便的还原出拉链时点的客户记录**。
4. 流水表： 对于表的每一个修改都会记录，可以用于反映实际记录的变更。 

#### 拉链表

拉链表是针对数据仓库设计中表存储数据的方式而定义的，顾名思义，所谓拉链，就是记录历史。**记录一个事物从开始，一直到当前状态的所有变化的信息**。



拉链表通常是对账户信息的历史变动进行处理保留的结果，流水表是每天的交易形成的历史；

流水表用于统计业务相关情况，拉链表用于统计账户及客户的情况

在数仓中，一般在数仓中通过增加**begin_date,en_date**来实现拉链表，分别表示记录的生命周期起点和终点



![image-20211110165229597](_images/BigDataNotes.assets/image-20211110165229597.png)



![image-20220103233412027](_images/BigDataNotes.assets/image-20220103233412027.png)



拉链表回滚

假设恢复到t天之前的数据，即未融合t天数据之前的拉链表，假设标记的开始日期和结束日期分别为s、t，具体分析如下：

```json
1 当t-1>e时，s数据、e数据在t天之前产生，保留即可
2 当t-1=e时，e数据在t天产生，需修改
3 当s<t<=e时，e数据在t+n天产生，需修改
4 当s>=t时，s数据、e数据在t+n天产生，删除即可
```





### ETL

**ETL**，是英文Extract-Transform-Load的缩写，用来描述将[数据]从来源端经过抽取（extract）、[转换]（transform）、加载（load）至目的端的过程。**ETL**一词较常用在[**数据仓库**]，但其对象并不限于数据仓库。







## 大数据发展

### 大数据总结

https://zhuanlan.zhihu.com/p/452628664?utm_source=wechat_session&utm_medium=social&utm_oi=597048781695488000&s_r=0

























面试题：

- 什么是数仓？
- 数仓的几个特点是什么？
- 什么是OLAP？什么是OLTP？区别是什么？
- 拉链表是什么？怎么实现拉链表？
- 同步又哪几种方式？
- 为什么要做增量？怎么做增量？
- 什么是ETL？





ELT







学习顺序

